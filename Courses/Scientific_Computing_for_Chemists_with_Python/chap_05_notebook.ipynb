{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chapter 5: Pandas","metadata":{},"id":"388811b9-2c96-49cb-b4a1-4cd0da8d9d26"},{"cell_type":"code","source":"%config InlineBackend.figure_format = 'svg'","metadata":{"tags":["remove-input"]},"execution_count":null,"outputs":[],"id":"c1a4e5c8-dd69-4ca5-bc3a-a75f9a97d094"},{"cell_type":"markdown","source":"While NumPy is the foundation of much of the SciPy ecosystem and provides very capable ndarray objects, it has a few shortcomings. The first is that NumPy arrays cannot hold different types of objects in a single array. For example, if we attempt to convert the following list containing integers, floats, and strings into an array, NumPy coverts all elements into strings as a way of making the object types uniform.","metadata":{},"id":"e5660c12-6591-49af-8f8f-2ce15c55c282"},{"cell_type":"code","source":"nums = [1, 2, 3, 'four', 5, 'six', 7.0]","metadata":{},"execution_count":null,"outputs":[],"id":"da1b7e80-b460-4ae1-9e7d-f72b3dd2ddb8"},{"cell_type":"code","source":"import numpy as np\nnp.array(nums)","metadata":{},"execution_count":null,"outputs":[],"id":"78102bc7-0d6f-4fa7-b5fe-48182ec5039e"},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[],"id":"c7f9960f-8c70-4998-948d-d10a3ae5e797"},{"cell_type":"code","source":"pip install -U xlrd","metadata":{},"execution_count":null,"outputs":[],"id":"97b37fc7-5263-4aab-8cb3-d4e7212e3ee5"},{"cell_type":"markdown","source":"The second shortcoming is that NumPy arrays do not support labels in the data. That is, columns cannot have labels describing what they contain like you might see in a well constructed spreadsheet. This burdens the user to keep track of which column contains what information. Finally, while NumPy contains a wealth of basic tools for working with data, there are still many operations that it does not support like grouping data based on the value of a particular column or the ability to merge two data sets with automatic alignment of analogous data.\n\nA data scientist named Wes McKinney created the pandas library which provides a wealth of additional tools for working with data, and possibly the most endearing feature, the ability to call data based on labels. Data columns and rows can contain human-readable labels that are used to access the data. Pandas still supports accessing data using indices if the user wishes to go that route, but the user can now access data without knowing which column it is in as long as the user knows the column label.\n    \nBy popular convention, the pandas library is imported with the `pd alias`, which is used here. This chapter also assumes the following imports.\n\n```{index} pandas\n```","metadata":{},"id":"c8ef85ec-aaca-44e9-a1e0-5420eea916de"},{"cell_type":"markdown","source":"\n## 5.1 Basic Pandas Objects\n\nTo support the wealth of features, pandas uses its own objects to hold data called a Series and a DataFrame, which are built on NumPy arrays. Because they are built on NumPy, many of the NumPy functions (e.g., `np.mean()`) work on pandas objects. The key difference between the a Series and DataFrame is that a Series is one-dimensional while a DataFrame is two-dimensional. Unlike a NumPy array, pandas objects have fixed dimensionality. There is a three-dimensional object called a *Panel*, but this will not be covered here as it is not often used.\n\n\n### 5.1.1 Series\n\n```{index} Series\n```\n\nWhile the pandas *Series* is restricted to being a single dimension, it can be as long as necessary to hold the data. A Series containing the atomic masses of the first five elements on the periodic table is generated below using the `pd.Series()` function. This function is always capitalized.","metadata":{},"id":"9cb2977d-4f05-4723-b798-bf6b92906511"},{"cell_type":"code","source":"mass = pd.Series([1.01,4.00,6.94,9.01,10.81])\nmass","metadata":{},"execution_count":null,"outputs":[],"id":"e69d3941-868d-499a-ab68-02456de5f64e"},{"cell_type":"markdown","source":"The right column is the actual data in the Series while the values on the left are the assigned indices for each value in the Series. The index column is not part of the dimensionality of the Series; it is metadata (i.e., data about the data). \n\nConsistent with list, tuples, and ndarrays, values in a Series can be accessed using indexing with square brackets as demonstrated below.","metadata":{},"id":"f752c97a-3caf-4574-ae31-a4dcb1a72225"},{"cell_type":"code","source":"mass[2]","metadata":{},"execution_count":null,"outputs":[],"id":"728c6312-800b-43b7-8f9f-556df562977b"},{"cell_type":"markdown","source":"Unlike other multi-element objects seen so far, data in a Series can be accessed using indices different from the default (i.e., 0, 1, 2, etc…) values. That is, custom indices can be assigned using the index argument shown below.","metadata":{},"id":"0e26a117-3895-441a-9556-5acf239e0810"},{"cell_type":"code","source":"index=('H', 'He', 'Li', 'Be', 'B')\nmass2 = pd.Series([1.01,4.00,6.94,9.01,10.81], index)\nmass2","metadata":{},"execution_count":null,"outputs":[],"id":"6cab7866-1e81-4643-bbc5-aecbb44b912b"},{"cell_type":"markdown","source":"The custom indices can now be used to access an element in a Series. This makes a Series behave something like a dictionary ([section 2.2](2.2)).","metadata":{},"id":"5b3adf8d-a999-476e-8044-2695483845d6"},{"cell_type":"code","source":"mass2['He']","metadata":{"tags":[]},"execution_count":null,"outputs":[],"id":"b6ed5bb1-ddbf-4158-99dc-e53473297838"},{"cell_type":"markdown","source":"The indices can be accessed by using `mass2.index`. Series indices can also be modified after a Series has been created by using `.index` and assignment as demonstrated below.","metadata":{},"id":"954b2159-01ea-494b-ae6f-fa52c23df097"},{"cell_type":"code","source":"mass.index =['H', 'He', 'Li', 'Be', 'B']\nmass","metadata":{},"execution_count":null,"outputs":[],"id":"068e1263-5820-4ef9-8ed2-12c76a7b7324"},{"cell_type":"markdown","source":"Even if we create or modify a Series to have custom indices, we can still access the elements using the traditional numerical indices using the `iloc[]` method. This method allows the user to access elements the same way as in a NumPy array regardless of assigned index values.","metadata":{},"id":"e29d87f1-79df-48da-ac86-d806393f33eb"},{"cell_type":"code","source":"mass2.iloc[2]","metadata":{},"execution_count":null,"outputs":[],"id":"7aba45e6-4c1c-46cb-89e4-6b0fbf927b57"},{"cell_type":"markdown","source":"\n### 5.1.2 DataFrame\n\n```{index} single: DataFrame; create\n```\n\nMost data you will find yourself working with will be best placed in a two-dimensional pandas object called a *DataFrame* which is always written with two capital letters. The DataFrame is similar to a Series except that now there are also columns with names. The columns can be accessed by column names and rows can be accesses by indices. You might think of a DataFrame as a collection of Series objects. Below, a DataFrame is constructed to hold the names, atomic numbers, masses, and ionization energies of the first five elements.","metadata":{},"id":"83f5b9c5-7feb-4190-9809-204c865afe03"},{"cell_type":"code","source":"name = ['hydrogen', 'helium', 'lithium', 'beryllium','boron']\nAN = [1,2,3,4,5]\nmass = [1.01,4.00,6.94,9.01,10.81]\nIE = [13.6, 24.6, 5.4, 9.3, 8.3]","metadata":{},"execution_count":null,"outputs":[],"id":"d73ca127-b530-435e-bd7a-7b12adf10ea4"},{"cell_type":"code","source":"columns = ['H', 'He', 'Li', 'Be','B'] \nindex = ['name', 'AN', 'mass', 'IE']\nelements = pd.DataFrame([name, AN, mass, IE], \n                        columns=columns, index=index)\nelements","metadata":{},"execution_count":null,"outputs":[],"id":"eb1f7acf-1354-4367-9df0-d7e9d33f8e71"},{"cell_type":"markdown","source":"To access data in a DataFrame, place the column name in square brackets.","metadata":{},"id":"6e3c1b48-b378-4864-9550-1a9f7a6c0d00"},{"cell_type":"code","source":"elements['Li']","metadata":{},"execution_count":null,"outputs":[],"id":"5b39ed3f-4e0d-4bc0-9b59-dc13d08d1623"},{"cell_type":"markdown","source":"Essentially what we get out of a column is a Series with the indices shown on the lefthand side.\n\nTo indicate a row, instead use the `loc[]` method. We again get a Series with indices derived from the column names in the source DataFrame. This Series can be placed in a variable and indexed just like in section [5.1.1](5.1.1).","metadata":{},"id":"2fd8f45e-68c6-4c80-8c29-5999729ebb00"},{"cell_type":"code","source":"elements.loc['IE']","metadata":{},"execution_count":null,"outputs":[],"id":"b14e20ee-337c-4bb0-bd9e-559a44a4a3d0"},{"cell_type":"code","source":"atomic_number = elements.loc['AN']","metadata":{},"execution_count":null,"outputs":[],"id":"7369b7f2-fa2a-4818-bd73-461c038b7441"},{"cell_type":"code","source":"atomic_number['B']","metadata":{},"execution_count":null,"outputs":[],"id":"044c4798-6522-4d6e-b0f3-b409dc1f331f"},{"cell_type":"markdown","source":"Alternatively, we can use the DataFrame directly and index it with the `loc[]` method as `[row, column]`.","metadata":{},"id":"e7140e95-6c64-4d69-8a85-49d392de5279"},{"cell_type":"code","source":"elements.loc['IE', 'Li']","metadata":{},"execution_count":null,"outputs":[],"id":"d6252065-b633-4f72-9de2-bccfac52e451"},{"cell_type":"markdown","source":"Numerical index values can also be used with the `iloc[]` method. This reduces indexing to how NumPy arrays are indexed.","metadata":{},"id":"66815349-3b84-4620-a27b-498016e257cd"},{"cell_type":"code","source":"elements.iloc[2:, 2]","metadata":{},"execution_count":null,"outputs":[],"id":"3fdef851-d9e4-43af-bf03-baed8f5c7f8e"},{"cell_type":"markdown","source":"A summary of the methods of indexing pandas Series and DataFrames is presented below in Table 1.\n\n**Table 1** Summary of Pandas Indexing\n\n| Index Method | Description |\n|:-----------: | :---------  |\n|`s[index]` | Index Series with assigned index values\n|`s.iloc[index]` | Index Series with default numerical index values |\n|`df[column]` | Index DataFrame with column name|\n|`df.loc[row]` | Index DataFrame with row name|\n|`df.loc[row, column]` | Index DataFrame with row and column names|\n|`df.iloc[row, column]` | Index DataFrame with row and column default numerical index values|\n","metadata":{},"id":"5a8a0015-ea31-4b7a-97d4-3e9888f605ca"},{"cell_type":"markdown","source":"\n## 5.2 Reading/Writing Data\n\n```{index} single: file input/output; with pandas\n```\n\nSimilar to NumPy, pandas contains multiple, convenient functions for reading/writing data directly to and from its own object types, and each function is suited to a specific file format. This includes CSV, HTML, JSON, SQL, Excel, and HDF5 files [among others](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).\n\n**Table 2** Import/Export Functions in Pandas\n\n| Function | Description |\n|:-------: | :---------  |\n|`read_csv()` and `to_csv()` | Imports/Exports data from/to a CSV file |\n|`read_table()` and `to_table()` | General-purpose importer/exporter |\n|`read_hdf5()` and `to_hdf5()` | Imports/Exports data from/to an HDF5 file |\n|`read_clipboard()` and `to_clipboard()` | Transfers data to/from the clipboard\\* to a Series or DataFrame |\n|`read_excel()` and `to_excel()` | Reads/writes an Excel file|\n\n\n### 5.2.1 General-Purpose Delimited File Reader\n\nBefore we start with more well-defined file formats, pandas provides a general purpose file reader `pd.read_table()`. This function imports text files where lines represent rows and the data in each row is separated by characters or spaces. The user can designate what character(s) separate the data by using the `delimiter` or `sep` arguments (they do the same thing),  or as an easy way of breaking up data based on spaces, set the  `delim_whitespaces` equal to `True`. The function also includes a series of other arguments listed below in Table 3.\n\n**Table 3** More `pd.read_table()` Arguments\n\n| Argument | Description |\n|:--------:| :-------    |\n|`delimiter`| Data separator; default is tab|\n|`sep` | Data separator; default is tab|\n|`skiprows` | Number of rows in file to skip before reading data|\n|`skipfooter` | Number of rows at the bottom of the file to skip|\n|`skip_blank_lines`| If `True`, skips blank lines in file; default is `False`|\n|`header` | Row number to use for a data header; also accepts None if no header is provided in the file|\n|`delim_whitespace` | Boolean argument indicating that data is separated by white space; default is `False`|\n|`skipinitialspace` | If `True`, skips white space after delimiter|\n\nAs an example, we can use this function to read a calculated PDB file of benzene and extract the $xyz$ coordinates for each atom. This particular file type, shown below, is [strictly formatted based on the position in a line](http://www.wwpdb.org/documentation/file-format), but being that all the data columns here have spaces between them, we can use space delimitation by setting  `delim_whitespace=True`. Because the data do not start until the third line and we do not need the last thirteen lines of the file, we should exclude these rows. We set `header=None` because we do not want the function to treat the first line of data as a header or data label.\n\n    HEADER \n    REMARK \n    HETATM    1  H   UNK  0001       0.000   0.000  -0.020 \n    HETATM    2  C   UNK  0001       0.000   0.000   1.067 \n    HETATM    3  C   UNK  0001       0.000   0.000   3.857 \n    HETATM    4  C   UNK  0001       0.000  -1.208   1.764 \n    HETATM    5  C   UNK  0001       0.000   1.208   1.764 \n    HETATM    6  C   UNK  0001       0.000   1.208   3.159 \n    HETATM    7  C   UNK  0001       0.000  -1.208   3.159 \n    HETATM    8  H   UNK  0001       0.000  -2.149   1.221 \n    HETATM    9  H   UNK  0001       0.000   2.149   1.221 \n    HETATM   10  H   UNK  0001       0.000   2.149   3.703 \n    HETATM   11  H   UNK  0001       0.000  -2.149   3.703 \n    HETATM   12  H   UNK  0001       0.000   0.000   4.943 \n    CONECT    1    2 \n    CONECT    2    1    5    4 \n    CONECT    3    6    7   12 \n    CONECT    4    7    2    8 \n    CONECT    5    2    6    9 \n    CONECT    6    5    3   10 \n    CONECT    7    3    4   11 \n    CONECT    8    4 \n    CONECT    9    5 \n    CONECT   10    6 \n    CONECT   11    7 \n    CONECT   12    3 \n    END","metadata":{},"id":"f11a704d-e354-4440-90d4-96ea4fd28570"},{"cell_type":"code","source":"import os \nos.environ['HTTP_PROXY'] = 'http://ga.dp.tech:8118'\nos.environ['HTTPS_PROXY'] = 'http://ga.dp.tech:8118'","metadata":{},"execution_count":null,"outputs":[],"id":"ceb412db-ec0e-4bee-b430-d1483f440e8b"},{"cell_type":"code","source":"benz = pd.read_table('https://raw.githubusercontent.com/weisscharlesj/SciCompforChemists/master/notebooks/chapter_05/data/benzene.pdb', delim_whitespace=True, \n                     skiprows=2, skipfooter=13, header=None, \n                     engine='python')","metadata":{},"execution_count":null,"outputs":[],"id":"c0d567b7-dcac-4fc1-b069-c641687dbef4"},{"cell_type":"code","source":"benz","metadata":{},"execution_count":null,"outputs":[],"id":"476acb3d-5c2f-4e28-97cf-9d593c825998"},{"cell_type":"markdown","source":" The $x$, $y$, and $z$ data are in columns 5, 6, and 7, respectively and can be extracted by indexing as discussed in [section 5.1.2](5.1.2).","metadata":{},"id":"66b68ed0-e92e-4531-8bf1-ef49e09226f6"},{"cell_type":"markdown","source":"\n### 5.2.2 Comma Separated Values Files\n\nPandas provides a collection of more format-specific functions for reading/writing files. The most popular is possibly the CSV file because it is simple and many scientific instruments support exporting data in this format. To import a CSV file, we will use the `read_csv()` function. This function is very similar to the `read_table()` function except that a default value for the separator/delimiter is set to a comma. To create a CSV file, use the `to_csv()` method which at a minimum requires the file name and a pandas object with the data.\n\nWe can write the above chemical element data assembled in [section 5.1](5.1) as shown below. Because we are starting from a pandas object and are using a pandas method, the `df.to_csv()` format is used where df is a DataFrame.\n\n~~~python\nelements.to_csv('elements.csv')\n~~~\n\nIf we check the directory containing the Jupyter notebook, the data folder contains a file titled *elements.csv* that looks like the following. Each row in the DataFrame is a different line in the file, and every column is separated by a comma.\n\n    ,H,He,Li,Be,B\n    name,hydrogen,helium,lithium,berylium,boron\n    AN,1,2,3,4,5\n    mass,1.01,4.0,6.94,9.01,10.81\n    IE,13.6,24.6,5.4,9.3,8.3\n\nTo read the data back in from the file, use `pd.read_csv()`. Because we are not starting with a pandas object, the function is called using the `pd.function()` format.","metadata":{},"id":"a09fd196-fc1e-40fc-ba21-5e0631798515"},{"cell_type":"code","source":"pd.read_csv('https://raw.githubusercontent.com/weisscharlesj/SciCompforChemists/master/notebooks/chapter_05/data/elements.csv')","metadata":{},"execution_count":null,"outputs":[],"id":"1869bdbe-be03-4f6f-b43c-00fc58f482c9"},{"cell_type":"markdown","source":"\n### 5.2.3 Excel Notebook Files\n\nPandas provides another useful function for importing Excel notebook files (i.e., *.xls* or *.xlsx*). Because Excel files can contain multiple sheets, this function is a little more complicated to use. The simplest way to import an Excel file is to use `pd.read_excel()` and provide it with the Excel file name.","metadata":{"tags":[]},"id":"f807e273-8abf-4424-9589-28848a7fe5dc"},{"cell_type":"code","source":"pd.read_excel('https://bohrium-example.oss-cn-zhangjiakou.aliyuncs.com/notebook/SciCompforChemists/notebooks/chapter_05/data/test.xls')","metadata":{},"execution_count":null,"outputs":[],"id":"a9175f3a-dc8b-4272-98f3-29b8b73cc7c3"},{"cell_type":"markdown","source":"In the above example, pandas assumes the first sheet in the file. If you want to access a different sheet in the file, you can specify this by using the `sheet_name` keyword argument. If you do not know the sheet name, the `sheet_name` argument also accepts integer index values (i.e., `0` for the first sheet and so on).","metadata":{},"id":"b191853c-0ea6-4e02-837c-9c9fcb762473"},{"cell_type":"code","source":"data = pd.read_excel('https://bohrium-example.oss-cn-zhangjiakou.aliyuncs.com/notebook/SciCompforChemists/notebooks/chapter_05/data/test.xls', sheet_name='Sheet2')\ndata","metadata":{},"execution_count":null,"outputs":[],"id":"d2ef9926-4b7a-4235-983c-2e34ba373964"},{"cell_type":"markdown","source":"Alternatively, if you want to extract the sheet names, you can use the `sheets_names` method with the `ExcelFile` class as demonstrated below.","metadata":{},"id":"cfc68738-92f8-4000-9802-0089d77afbee"},{"cell_type":"code","source":"xl = pd.ExcelFile('https://bohrium-example.oss-cn-zhangjiakou.aliyuncs.com/notebook/SciCompforChemists/notebooks/chapter_05/data/test.xls')\nxl.sheet_names","metadata":{},"execution_count":null,"outputs":[],"id":"518192c2-05ac-48a5-9685-c8372fd48499"},{"cell_type":"markdown","source":"Writing to an Excel file requires two steps – generate an ExcelWriter engine and then write each sheet. The Excel writer offers more power in generating Excel files including embedding charts, conditional formatting, coloring cells, and other tasks; but we will stick to the basics here.","metadata":{},"id":"dddb5047-29cc-467c-af69-ceaa616bac93"},{"cell_type":"code","source":"writer = pd.ExcelWriter('new_file.xlsx')\ndata.to_excel(writer, 'First Sheet')\n# writer.save()\nwriter.close()","metadata":{},"execution_count":null,"outputs":[],"id":"6b067bb6-0786-4855-a238-f576cd61ff50"},{"cell_type":"markdown","source":"\n### 5.2.4 Computer Clipboard\n\nPandas will also accept data from the computer’s copy and paste clipboard. Start by highlighting some data from a webpage or a spreadsheet, select copy. This is typically located under the Edit menu of most software applications. Alternatively, you can type Command + C on a macOS or Control + C on Windows and Linux. Finally, use the `pd.read_clipboard()` function to convert it to a pandas DataFrame.\n\n~~~python\npd.read_clipboard()\n~~~\n\nLoading data from the clipboard is not a robust and efficient way to do much of your automated data analysis, but it is a very convenient method to experiment with data or to quickly grab some data off a website to experiment with.","metadata":{},"id":"3e7db82d-2458-43c6-90cc-378a2e60b159"},{"cell_type":"markdown","source":"\n## 5.3 Examining Data with Pandas\n\nOnce you load data into pandas, you will likely want to get an idea of what the data look like before you proceed to calculations and in-depth analyses. This section covers a few methods provided in pandas to gain a preliminary understanding of your data.\n\n### 5.3.1 Descriptive Functions\n\n```{index} single: DataFrame; statistics\n```\n\nPandas provides a few simple functions to view and describe new data. The first two are `head()` and `tail()` which allow you to see the top and bottom of the DataFrame, respectively. These are particularly useful when dealing with very large DataFrames. Below, a DataFrame containing random values in an even, normal, and poisson distribution ($\\lambda$ = 3.0) demonstrates these functions.","metadata":{},"id":"4fb391da-4a0d-4d8c-9e27-d3ccfe7ad0a6"},{"cell_type":"code","source":"random = pd.DataFrame({'even': np.random.rand(1000),\n                       'normal': np.random.randn(1000),\n                       'poisson': np.random.poisson(\n                        lam=3.0, size=1000)})","metadata":{},"execution_count":null,"outputs":[],"id":"dd4ae599-a8b0-4b95-957e-aa71e075a304"},{"cell_type":"code","source":"random.head()","metadata":{},"execution_count":null,"outputs":[],"id":"ae940235-09dd-4060-a7bc-8a1307c9f0c2"},{"cell_type":"code","source":"random.tail()","metadata":{},"execution_count":null,"outputs":[],"id":"db1014b9-9f90-45de-9033-fc6b5f9c8673"},{"cell_type":"markdown","source":"Pandas also contains a `describe()` function that returns a variety of statistics on each column. For example, the mean is provided which are approximately 0.5, 0.0, and 3.0 for the even, normal, and poisson distributions, respectively. This is not surprising being that the even distribution is centered around 0.5, the normal around 0.0, and the poisson distribution is generated for an average of 3.0. The user is also provided with the minimum, maximum, standard deviation, and the quartile boundaries.","metadata":{},"id":"53731447-51f1-44e6-a0cf-e6693d88c39f"},{"cell_type":"code","source":"random.describe()","metadata":{},"execution_count":null,"outputs":[],"id":"3bc58822-787f-405f-8fda-30a68dea60bc"},{"cell_type":"markdown","source":"Another useful function is the `value_counts()` method which returns all unique values in a Series (or DataFrame column or row). Below, it is demonstrated on the poisson column being that the other two columns will have a relatively large number of unique values.","metadata":{},"id":"53a06711-1356-4416-b1f9-62ca6f75aebc"},{"cell_type":"code","source":"counts = random['poisson'].value_counts()\ncounts","metadata":{},"execution_count":null,"outputs":[],"id":"87b3d2b7-9b7c-4646-8a42-b8c8f0c37daa"},{"cell_type":"markdown","source":"Data in DataFrames can be plotting by calling the desired columns of data and feeding them into plotting functions like `plt.scatter()`. The data can also be visualized by using the `df.plot(kind=)` format where `df` is the DataFrame and `kind` is the plot type (e.g., `'bar'`, `'hist'`, `'scatter'`, `'line'`, `'pie'`, etc...). However, this is just matplotlib doing the plotting and is largely redundant with other methods already covered. Below is a quick example of the counts data generated above.","metadata":{},"id":"5267bab5-f8cc-4c60-b981-27b10d514385"},{"cell_type":"code","source":"counts.plot(kind='bar')","metadata":{},"execution_count":null,"outputs":[],"id":"035f75a3-a7b9-49fc-abbb-f97967c9b8e3"},{"cell_type":"markdown","source":"\n### 5.3.2 Broadcasted Mathematical Operations\n\nBecause pandas is built upon NumPy arrays, mathematical operations are propagated through Series and DataFrames. The user is able to use NumPy methods on pandas objects, and there are a number of other mathematical operations to chose from such as those listed below.\n\n**Table 4** Broadcasted Pandas Methods\n\n| Function | Description |\n|:-------: | :---------  |\n|`abs()` | Absolute value |\n|`count()` | Counts items |\n|`cumsum()` | Cumulative sum |\n|`cumprod()` | Cumulative product |\n|`mad()` | Mean absolute deviation |\n|`max()` | Maximum |\n|`min()` | Minimum |\n|`mean()` | Mean |\n|`median()` | Median |\n|`mode()` | Mode |\n|`std()` | Standard deviation|\n\n````{margin}\n```{note}\nThe default delta degree of freedom (`ddof`) of the `std()` function in pandas equals one unlike Microsoft Excel or NumPy ([see section 4.5](4.5)) where the default is zero. This behavior can be modified with the `ddof=1` argument.\n```\n````","metadata":{},"id":"f186434e-2afd-4509-b310-7dcdcba7db60"},{"cell_type":"markdown","source":"\n## 5.4 Modifying DataFrames\n\nNow that you are able to generate DataFrames, it is useful to be able to modify them as you clean your data or perform calculations. This can be done through methods such as assignment, dropping rows and columns, and combining DataFrames or Series.\n\n\n### 5.4.1 Insert Columns via Assignment\n\n```{index} single: DataFrame; insert columns\n```\n\nPossibly the easiest method of adding a new column is through assignment. If a nonexistent column is called and assigned values, instead of returning an error, pandas creates a new column with the given name and populates it with the data. For example, the `elements` DataFrame below does not contain a carbon column, so the column is added when assigned to a Series with the data. ","metadata":{},"id":"215893fa-48a7-44a6-8ae5-0b5338d5e0ae"},{"cell_type":"code","source":"elements","metadata":{},"execution_count":null,"outputs":[],"id":"20ad5471-516a-461c-be25-931dd1f71418"},{"cell_type":"code","source":"elements['C'] = ['carbon', 6, 12.01, 11.3]\nelements","metadata":{},"execution_count":null,"outputs":[],"id":"a9679e58-46d2-4adf-9e38-a32fb47a4f9b"},{"cell_type":"markdown","source":"\n### 5.4.2 Automatic Alignment\n\nAnother important feature of pandas is the ability to automatically align data based on labels. In the above example, carbon is added to the DataFrame with the name, atomic number, atomic mass, and ionization energy in the same order as in the DataFrame. What happens if the new data is not in the correct order? If we are using NumPy, this would require additional effort on the part of the user to reorder the data. However, if each value is labeled, pandas will see to it that they are placed in the correct location.","metadata":{},"id":"2fc3ab46-b5bb-47b3-8a2f-ef551601099f"},{"cell_type":"code","source":"nitrogen = pd.Series([7, 14.01, 'nitrogen', 14.5], \n                     index=['AN', 'mass', 'name', 'IE'])\nnitrogen","metadata":{},"execution_count":null,"outputs":[],"id":"240bc5a6-6b68-4cc2-8c97-7b8557b558f2"},{"cell_type":"markdown","source":"Data for nitrogen is placed in a Series above. Notice that the values are out of order with respect to the data in `elements`. There are index labels (i.e., row labels) that tell pandas what each piece of data is, and pandas will use them to determine where to place the new information.","metadata":{},"id":"cdad4371-7e44-44e3-b3d0-cfb2810f75e4"},{"cell_type":"code","source":"elements['N'] = nitrogen\nelements","metadata":{"tags":[]},"execution_count":null,"outputs":[],"id":"a3ed4e58-dde9-47b9-acae-99f627c47d1f"},{"cell_type":"markdown","source":"The new column of nitrogen data has been added to `elements` with all pieces of data residing in the correct row.","metadata":{},"id":"6655c619-d888-4e0c-bccb-cfc288b75086"},{"cell_type":"markdown","source":"\n### 5.4.3 Dropping Columns\n\n```{index} single: DataFrame; drop columns\n```\n\nWhen cleaning up data, you may wish to drop a column or row. Pandas provides the `drop()` method for this purpose. It requires the name of the column or row to be dropped, and by default, it assumes a row, `axis=0`, is to be dropped. If you want to drop a column, change the axis using the `axis=1` argument. Below, the hydrogen column is dropped from the elements DataFrame.","metadata":{"tags":[]},"id":"5f7bad29-a763-46a6-873d-8b771bbdf16a"},{"cell_type":"code","source":"elements.drop('H', axis=1)","metadata":{},"execution_count":null,"outputs":[],"id":"037a69fe-ceba-4f45-9a11-4a1e6294e486"},{"cell_type":"code","source":"elements.drop('IE', axis=0)","metadata":{},"execution_count":null,"outputs":[],"id":"b87a2c00-d9b0-4923-9c14-ead239b17e6d"},{"cell_type":"markdown","source":"In the second example above, the hydrogen is back despite being previously dropped. This is because the `drop()` method does not by default modify the origional DataFrame. To make the changes perminent, either assigned the new DataFrame to a new variable or add the `inplace=True` keyword argument to the above `drop()` function.\n\n```{index} single: missing values; with pandas\n```\n\nThere is a similar function `pd.dropna()` that drops columns or rows from a DataFrame that contain `nan` values. This is commonly used to remove incomplete data from a data set. The `pd.dropna()` function behaves very similarily to the `pd.drop()` function including the `inplace=` and `axis=` arguments.","metadata":{},"id":"bb8f8569-5814-40f9-b1a7-10f099de69c5"},{"cell_type":"markdown","source":"\n### 5.4.4 Merge\n\n```{index} single: DataFrame; merge\n```\n\nTo merge multiple DataFrames, pandas provides a `merge()` method. Similar to above, the `merge()` function will properly align data, but because DataFrames have multiple columns and index values to choose from, the `merge()` function can align data based on any of these values. The default behavior for `merge()` is to check for common columns between the two DataFrames and align the data based on those columns. As an example, below are two DataFrames containing data from various chemical compounds.","metadata":{},"id":"3f237427-2414-45db-8b88-529b88220504"},{"cell_type":"code","source":"chemdata1 = [['MW', 58.08, 32.04], ['dipole', 2.91, 1.69], \n             ['formula', 'C3H6O', 'CH3OH']] \ncolumns=['property','acetone', 'methanol']\nchmdf1 = pd.DataFrame(chemdata1, columns=columns)","metadata":{},"execution_count":null,"outputs":[],"id":"a7186aeb-b501-40e8-99ba-c8a32120a57e"},{"cell_type":"code","source":"chmdf1","metadata":{},"execution_count":null,"outputs":[],"id":"c801763d-0031-48bf-a820-7c9f7b9979c6"},{"cell_type":"code","source":"chmdata2 = [['formula', 'C6H6', 'H2O'], ['dipole', 0.00, 1.85], \n            ['MW', 78.11, 18.02]]\nchmdf2 = pd.DataFrame(chmdata2 , columns=['property', 'benzene', 'water'])","metadata":{},"execution_count":null,"outputs":[],"id":"22e8ccc7-5237-4184-a6f8-d4c9a6930cce"},{"cell_type":"code","source":"chmdf2","metadata":{},"execution_count":null,"outputs":[],"id":"00287786-e1da-48d4-ab5d-fd5d852f954e"},{"cell_type":"markdown","source":"Both DataFrames above have a `property` column, so the `merge()` function uses this common column to align all the data into a new DataFrame.","metadata":{},"id":"b822c783-fc2e-400e-80ca-c1a173d004d9"},{"cell_type":"code","source":"chmdf1.merge(chmdf2)","metadata":{},"execution_count":null,"outputs":[],"id":"41a143a9-81f9-44ad-b8f6-e0ae913a1e2e"},{"cell_type":"markdown","source":"If there are multiple columns with the same name, the user can specify which to use with the `on` keyword argument (e.g., `on='property'`). Alternatively, if the two DataFrames contain columns with different names that the user wants used for alignment, the user can specify which columns to use with the `left_on` and `right_on` keyword arguments.","metadata":{},"id":"5a548922-ed9e-4495-a70e-e426c399248a"},{"cell_type":"code","source":"comps1 = pd.DataFrame({'element':['Co', 'Fe', 'Cr','Ni'], \n                       'protons': [27, 26, 24, 28]})\ncomps2 = pd.DataFrame({'metal':['Fe', 'Co', 'Cr', 'Ni'], \n                       'IE': [7.90, 7.88, 6.79, 7.64]})","metadata":{},"execution_count":null,"outputs":[],"id":"ef02eae7-15ba-4977-a69c-2ccb440abd85"},{"cell_type":"markdown","source":"In the two DataFrames generated above, each contains data on on cobalt, iron, chromium, and nickel; but the first DataFrame labels metals as `element` while the second labels the metals as `metal`. The following merges the two DataFrames based on values in these two columns.","metadata":{},"id":"dd45cdab-4404-49af-8a22-02ecb0e33910"},{"cell_type":"code","source":"comps1.merge(comps2, left_on='element',right_on='metal')","metadata":{},"execution_count":null,"outputs":[],"id":"396a6f7e-4949-4312-9e5f-b933b87bd536"},{"cell_type":"markdown","source":"Notice that the values in the `element` and `metal` columns were aligned in the resulting DataFrame. To get rid of one of the redundant columns, just use the `drop()` method described in [section 5.4.3](5.4.3).","metadata":{},"id":"1230094b-84cd-414c-a941-94b478ea5cf6"},{"cell_type":"code","source":"comps3 = comps1.merge(comps2, left_on='element', \n                      right_on='metal')\ncomps3.drop('metal', axis=1, inplace=True)\ncomps3","metadata":{},"execution_count":null,"outputs":[],"id":"81af77cf-eba8-4fcb-aefd-ac09b7e84e56"},{"cell_type":"markdown","source":"\n### 5.4.5 Concatenation\n\n```{index} single: DataFrame; concatenation\n```\n\nConcatenation is the process of splicing two DataFrames along a given axis. This is different from the `merge()` method above in that `merge()` merges and aligns common data between the two DataFrames while `pd.concat()` blindly appends one DataFrame to another. As an example, imagine two lab groups measure the densities of magnesium, aluminum, titanium, and iron and load their results into DataFrames below. ","metadata":{},"id":"db88e80f-67f2-4b5a-820f-a71cb5cb9126"},{"cell_type":"code","source":"group1 = pd.DataFrame({'metal':['Mg', 'Al', 'Ti', 'Fe'], \n                       'density': [1.77, 2.73, 4.55, 7.88]})\ngroup2 = pd.DataFrame({'metal':['Al', 'Mg', 'Ti', 'Fe'], \n                       'density': [2.90, 1.54, 4.12, 8.10]})","metadata":{},"execution_count":null,"outputs":[],"id":"9ec72107-6d86-4131-ac8c-5e244b7e9f03"},{"cell_type":"code","source":"group1","metadata":{},"execution_count":null,"outputs":[],"id":"c6e2db3b-6952-4f19-93ac-8b5ea6f76a3d"},{"cell_type":"markdown","source":"See what happens when these two DataFrames are concatenated.","metadata":{},"id":"8c2fbfc2-a4b1-4cca-8edb-1394fc2646d8"},{"cell_type":"code","source":"pd.concat((group1, group2))","metadata":{},"execution_count":null,"outputs":[],"id":"d5317a99-fe12-4e42-ad0c-22a1003a424e"},{"cell_type":"markdown","source":"Notice how the two DataFrames are appended with no consideration for common values in the `metal` column. The default behavior is to concatenate along the first axis (`axis=0`), but this behavior can be modified with the `axis=` keyword argument. Again, the metals are not all aligned below because they were not in the same order in the original DataFrames.","metadata":{},"id":"29254e9c-b3de-4504-8b7e-e721a2cb1b71"},{"cell_type":"code","source":"pd.concat((group1, group2), axis=1)","metadata":{},"execution_count":null,"outputs":[],"id":"7d0eeeb1-02fd-4540-897e-880b6c1e159f"},{"cell_type":"markdown","source":"For comparison, if the two DataFrames are merged instead of concatenating them, pandas will align the data based on the `metal` as demonstrated below. Because `density` appears twice as a column header, pandas deals with this by adding a suffix to differentiate between the two data sets.","metadata":{},"id":"3bebe3f4-4e71-4c1e-bc45-db9ea4bdbd9a"},{"cell_type":"code","source":"pd.merge(group1, group2, on='metal')","metadata":{},"execution_count":null,"outputs":[],"id":"86511232-16e8-4983-bd6c-a290f10232b6"},{"cell_type":"markdown","source":"## Further Reading\n\nFor further resources on the pandas library, see the following. The value of the pandas website cannot be emphasized enough as it contains a large quantity of high quality documentation and illustrative examples on using pandas for data analysis and processing.\n\n1. Pandas Website. [http://pandas.pydata.org/](http://pandas.pydata.org/) (free resource)\n\n2. VanderPlas, J. Python data Science Handbook: Essential Tools for Working with Data, 1st ed.; O’Reilly: Sebastopol, CA, 2017, chapter 3. A free, online version is available by the author at [https://github.com/jakevdp/PythonDataScienceHandbook](https://github.com/jakevdp/PythonDataScienceHandbook) (free resource)\n\n3. McKinney, W. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and Ipython, 2nd ed.; O’Reilly: Sebastopol, CA, 2018.","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]},"id":"f61d745b-714e-47d3-bb87-8ed3af7c4fac"},{"cell_type":"markdown","source":"## Exercises\n\nComplete the following exercises in a Jupyter notebook using the pandas library. Avoid using `for` loops unless absolutely necessary. Any data file(s) refered to in the problems can be found in the [data](https://github.com/weisscharlesj/SciCompforChemists/tree/master/notebooks) folder in the same directory as this chapter's Jupyter notebook. Alternatively, you can download a zip file of the data for this chapter from [here](https://github.com/weisscharlesj/data_SciCompforChem) by selecting the appropriate chapter file and then clicking the **Download** button.","metadata":{},"id":"88a14e8d-9917-4418-bfad-956328edf650"},{"cell_type":"markdown","source":"1. Below is a table containing the melting points and boiling points of multiple common chemical solvents.\n\n    |  Solvent  |  bp  |  mp  |\n    |  :------: | :--: | :--: |\n    | benzene  | 80 | 6 |\n    | acetone | 56 | -95 |\n    | toluene | 111 | -95 |\n    | pentane |  36 | -130 |\n    | ether | 35 | -116 |\n    | ethanol | 78 | -114 |\n    | methanol | 65 | -98 |\n\n\n    \n    a) Create a Series containing the boiling points of the above solvents with the solvent names as the indices. Call the Series to look up the boiling point of ethanol.\n    \n    b) Create a DataFrame that contains both the boiling points and melting points with the solvent names as the indices. Call the DataFrame to look up the melting point of benzene.\n      \n    c) Access the boiling point of pentane in the DataFrame from part b using numerical indices.\n    \n2. Import the attached file **blue1.csv** containing the absorption spectrum of Blue 1 food dye using pandas.\n\n    a) Set the wavelengths as the index values.\n             \n    b) Plot the absorption versus wavelength.\n             \n    c) Determine the absorbance of Blue 1 at 620 nm.\n\n3. Chemical Kinetics: Import the file **kinetics.csv** containing time series data for the conversion of A $\\rightarrow$ Product using pandas IO tools. Generate new columns for $ln[A]$, $[A]^{-1}$, and $[A]^{0.5}$ and determine the order of the reaction.\n\n4. Import the **ROH_data.csv** file containing data on various simple alcohols to a DataFrame. Notice that this data is missing densities for some of the compounds. \n\n    a) Use pandas to remove any rows with incomplete information in the density column using the `pd.dropna()`           function. Check the DataFrame to see if it has changed.\n\n    b) Again using the `pd.dropna()` function, drop incomplete row with the parameter `inplace=True`. Check to see if the     DataFrame has changed.\n\n5. Import the following four files containing UV-vis spectra of four food dyes with the first column listing the wavelengths (nm) and the second column containing the absorbances. Each file contains data in from 400-850 nm in 1 nm increments.\n\n    $$ red40.csv \\quad green3.csv \\quad  blue1.csv \\quad yellow6.csv $$\n\n    a) Concatenation the files into a single DataFrame with the first column as the wavelength (nm) and the other         four columns as the absorbances for each dye.\n\n    b) Replace the column headers with meaningful labels.\n\n6. Import the two files **alcohols.csv** and **alkanes.csv** containing the boiling points of the two classes of organic compounds with respect to the number of carbons in each compound.\n\n    a) Drop the columns containing the names of the compounds.\n\n    b) Merge the two DataFrames allowing pandas to align the two DataFrames based on carbon number.\n","metadata":{},"id":"931217ad-9781-4037-b7eb-0369d747d142"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"78135651-8348-4a78-9fad-6067db1b3082"}]}
{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unconditional image generation","metadata":{}},{"cell_type":"markdown","source":"Unconditional image generation is a relatively straightforward task. The model only generates images - without any additional context like text or an image - resembling the training data it was trained on.\n\nThe [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline) is the easiest way to use a pre-trained diffusion system for inference.\n\nStart by creating an instance of [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline) and specify which pipeline checkpoint you would like to download.\nYou can use any of the ðŸ§¨ Diffusers [checkpoints](https://huggingface.co/models?library=diffusers&sort=downloads) from the Hub (the checkpoint you'll use generates images of butterflies).\n\n<Tip>\n\nðŸ’¡ Want to train your own unconditional image generation model? Take a look at the training [guide](https://huggingface.co/docs/diffusers/main/en/using-diffusers/training/unconditional_training) to learn how to generate your own images.\n\n</Tip>\n\nIn this guide, you'll use [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline) for unconditional image generation with [DDPM](https://arxiv.org/abs/2006.11239):","metadata":{}},{"cell_type":"code","source":"pip install diffusers transformers","metadata":{},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nRequirement already satisfied: diffusers in /opt/conda/lib/python3.8/site-packages (0.15.1)\nCollecting transformers\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d8/a7/a6ff727fd5d96d6625f4658944a2ae230f0c75743a9a117fbda013b03d3d/transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from diffusers) (6.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from diffusers) (1.23.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from diffusers) (9.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from diffusers) (2022.6.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from diffusers) (3.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from diffusers) (2.28.2)\nRequirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.8/site-packages (from diffusers) (0.13.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.14.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers) (3.0.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers) (3.4)\nInstalling collected packages: transformers\nSuccessfully installed transformers-4.28.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"}]},{"cell_type":"code","source":"import os \nos.environ['HTTP_PROXY'] = 'http://ga.dp.tech:8118'\nos.environ['HTTPS_PROXY'] = 'http://ga.dp.tech:8118'","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from diffusers import DiffusionPipeline\n\ngenerator = DiffusionPipeline.from_pretrained(\"anton-l/ddpm-butterflies-128\")","metadata":{},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a44efd10fad4ba8a1b8abbf28fc978f","version_major":2,"version_minor":0},"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13fb7fbe7e924bf1922f6620fa4502a1","version_major":2,"version_minor":0},"text/plain":"Downloading (â€¦)5cb/unet/config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee57fa6ed57a4d8fb8f2a0df29de698a","version_major":2,"version_minor":0},"text/plain":"Downloading (â€¦)on_pytorch_model.bin:   0%|          | 0.00/455M [00:00<?, ?B/s]"},"metadata":{}},{"name":"stderr","output_type":"stream","text":"Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n```\npip install accelerate\n```\n.\n"}]},{"cell_type":"markdown","source":"The [DiffusionPipeline](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline) downloads and caches all modeling, tokenization, and scheduling components. \nBecause the model consists of roughly 1.4 billion parameters, we strongly recommend running it on a GPU.\nYou can move the generator object to a GPU, just like you would in PyTorch:","metadata":{}},{"cell_type":"code","source":"generator.to(\"cuda\")","metadata":{},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DDPMPipeline {\n  \"_class_name\": \"DDPMPipeline\",\n  \"_diffusers_version\": \"0.15.1\",\n  \"scheduler\": [\n    \"diffusers\",\n    \"DDPMScheduler\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DModel\"\n  ]\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"Now you can use the `generator` to generate an image:","metadata":{}},{"cell_type":"code","source":"image = generator().images[0]","metadata":{},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d342b8f7c4f643769847730f8da5c792","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]"},"metadata":{}}]},{"cell_type":"markdown","source":"The output is by default wrapped into a [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class) object.\n\nYou can save the image by calling:","metadata":{}},{"cell_type":"code","source":"image.save(\"generated_image.png\")","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Try out the Spaces below, and feel free to play around with the inference steps parameter to see how it affects the image quality!\n\n<iframe\n\tsrc=\"https://stevhliu-ddpm-butterflies-128.hf.space\"\n\tframeborder=\"0\"\n\twidth=\"850\"\n\theight=\"500\"\n></iframe>","metadata":{}}]}